{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from pandas import read_csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"./dataset_minecraft.csv\" is loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "# LOAD dataset\n",
    "dataset_path = './dataset_minecraft.csv'\n",
    "df = read_csv(dataset_path)\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "print(\"\\\"{}\\\" is loaded succesfully\".format(dataset_path))\n",
    "\n",
    "dataset = df['Text Clean'].to_numpy()\n",
    "label = df['Sentiment'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_train, feature_test, label_train, label_test = train_test_split(dataset, label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Word Length :\u001b[1m 88\n",
      "\n",
      "Unique words :\u001b[1m 14000\n",
      "\n",
      "===Feature Encoder Test=== \n",
      "Text Original :  game nya bagus serutapi freeze kamera detik menggangu survivalsaya bikin lag frame drop freeze kamera baik cepat baik\n",
      "Text Encoded  :  [1, 2, 3, 1548, 132, 466, 143, 346, 4902, 39, 42, 81, 78, 132, 466, 6, 133, 6]\n",
      "\n",
      "===Feature Decoder Test=== \n",
      "Text Sequence :  [1, 2, 3, 1548, 132, 466, 143, 346, 4902, 39, 42, 81, 78, 132, 466, 6, 133, 6]\n",
      "Text Decoded  :  game nya bagus serutapi freeze kamera detik menggangu survivalsaya bikin lag frame drop freeze kamera baik cepat baik\n",
      "\n",
      "Padding Test : \n",
      "Text Ori   :  game nya bagus serutapi freeze kamera detik menggangu survivalsaya bikin lag frame drop freeze kamera baik cepat baik\n",
      "Text Token :  [1, 2, 3, 1548, 132, 466, 143, 346, 4902, 39, 42, 81, 78, 132, 466, 6, 133, 6]\n",
      "Token Pad  :  [   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    2    3 1548  132  466  143  346 4902   39   42   81   78  132  466    6  133    6]\n"
     ]
    }
   ],
   "source": [
    "# MAX WORD LENGTH\n",
    "word_len = []\n",
    "for word in dataset:\n",
    "    word_len.append(len(word.split()))\n",
    "max_word_length = max(word_len)\n",
    "print(\"Max Word Length :\\033[1m\", max_word_length)\n",
    "####################################################################################\n",
    "\n",
    "# UNIQUE WORDS\n",
    "def counter_word(texts):\n",
    "    count = Counter()\n",
    "    for text in texts.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count\n",
    "\n",
    "counter = counter_word(df['Text Clean'])\n",
    "num_unique_words = len(counter) # 14000\n",
    "print(\"\\nUnique words :\\033[1m\", num_unique_words)\n",
    "####################################################################################\n",
    "\n",
    "# TOKENIZING\n",
    "# tokenizing dataset\n",
    "tokenizer = Tokenizer(num_words=num_unique_words)\n",
    "tokenizer.fit_on_texts(dataset)\n",
    "# print(tokenizer.word_index.keys())\n",
    "# print(tokenizer.word_index.values())\n",
    "####################################################################################\n",
    "\n",
    "# FEATURE ENCODER\n",
    "# dictionary for word\n",
    "word_index = tokenizer.word_index\n",
    "# turn dataset to sequence\n",
    "dataset_seq = tokenizer.texts_to_sequences(dataset)\n",
    "print(\"\\n===Feature Encoder Test=== \")\n",
    "print(\"Text Original : \", dataset[6])\n",
    "print(\"Text Encoded  : \", dataset_seq[6])\n",
    "####################################################################################\n",
    "\n",
    "# FEATURE DECODER\n",
    "# Flip word dictionary (key, value)\n",
    "reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])\n",
    "def decode(sequence):\n",
    "    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "decoded_text = decode(dataset_seq[6])\n",
    "print(\"\\n===Feature Decoder Test=== \")\n",
    "print(\"Text Sequence : \", dataset_seq[6])\n",
    "print(\"Text Decoded  : \", decoded_text)\n",
    "####################################################################################\n",
    "\n",
    "# Padding\n",
    "dataset_padded = pad_sequences(dataset_seq, maxlen=max_word_length, padding=\"pre\", truncating=\"pre\")\n",
    "print(\"\\nPadding Test : \")\n",
    "print(\"Text Ori   : \", dataset[6])\n",
    "print(\"Text Token : \", dataset_seq[6])\n",
    "print(\"Token Pad  : \", dataset_padded[6])\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Label Encoder Test=== \n",
      "['x0_negative' 'x0_neutral' 'x0_positive']\n",
      "Onehot \"negative\" : [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# LABEL ENCODE\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "label_one_hot = encoder.fit_transform(label.reshape(-1, 1))\n",
    "print(\"\\n===Label Encoder Test=== \")\n",
    "print(encoder.get_feature_names_out())\n",
    "print(\"Onehot \\\"{}\\\" : {}\".format(df['Sentiment'][0], label_one_hot[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "x_over, y_over = smote.fit_resample(dataset_padded, label_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    7034\n",
       "negative    6122\n",
       "neutral     1481\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEFORE OVERSAMPLING\n",
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "negative    7034\n",
       "positive    7034\n",
       "neutral     7034\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER OVERSAMPLING\n",
    "def decoderOnehot(data):\n",
    "    label = encoder.inverse_transform([data])\n",
    "    return label[0][0]\n",
    "    \n",
    "new_df = pd.DataFrame(list(zip(x_over, y_over)), columns=['features', 'label'])\n",
    "new_df['label'] = new_df['label'].apply(decoderOnehot)\n",
    "new_df['label'].value_counts()\n",
    "# new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21102, 88) (21102, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_over.shape, y_over.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_over, y_over, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label   \n",
       "neutral     4945\n",
       "negative    4916\n",
       "positive    4910\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(zip(y_train), columns=['label'])\n",
    "train_df['label'] = train_df['label'].apply(decoderOnehot)\n",
    "train_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label   \n",
       "positive    2124\n",
       "negative    2118\n",
       "neutral     2089\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(zip(y_test), columns=['label'])\n",
    "test_df['label'] = test_df['label'].apply(decoderOnehot)\n",
    "test_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CALLBACK\n",
    "class myCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.92 and logs.get('val_accuracy') >= 0.92):\n",
    "            self.ltm.stop_training=True\n",
    "            print('\\nModel telah mencapai akurasi 92%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 88, 64)            896000    \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirect  (None, 88, 128)           66048     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirect  (None, 128)               98816     \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1069315 (4.08 MB)\n",
      "Trainable params: 1069315 (4.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "wordEmbedding = layers.Embedding(\n",
    "                        input_dim=num_unique_words, \n",
    "                        output_dim=64, \n",
    "                        input_length=max_word_length,\n",
    "                        mask_zero=True                  # cuz i use zero padding so model will ignore 0 value\n",
    "                        )\n",
    "\n",
    "lstm = Sequential([\n",
    "    wordEmbedding,\n",
    "    # layers.Bidirectional(layers.LSTM(88, dropout=0.2, kernel_regularizer=l2(0.01))),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.3, kernel_regularizer=l2(0.01))),\n",
    "    layers.Bidirectional(layers.LSTM(64, dropout=0.3, kernel_regularizer=l2(0.01))),\n",
    "    # layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "lstm.summary()\n",
    "\n",
    "lstm.compile(loss=categorical_crossentropy,\n",
    "             optimizer=Adam(learning_rate=0.00001),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "231/231 [==============================] - 104s 451ms/step - loss: 6.2515 - accuracy: 0.3262 - val_loss: 6.1132 - val_accuracy: 0.3262\n",
      "Epoch 2/500\n",
      "231/231 [==============================] - 83s 360ms/step - loss: 5.9807 - accuracy: 0.3411 - val_loss: 5.8489 - val_accuracy: 0.3511\n",
      "Epoch 3/500\n",
      "231/231 [==============================] - 81s 351ms/step - loss: 5.7224 - accuracy: 0.3486 - val_loss: 5.5966 - val_accuracy: 0.3772\n",
      "Epoch 4/500\n",
      "231/231 [==============================] - 81s 353ms/step - loss: 5.4759 - accuracy: 0.3537 - val_loss: 5.3555 - val_accuracy: 0.3876\n",
      "Epoch 5/500\n",
      "231/231 [==============================] - 80s 345ms/step - loss: 5.2397 - accuracy: 0.3604 - val_loss: 5.1242 - val_accuracy: 0.3781\n",
      "Epoch 6/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 5.0131 - accuracy: 0.3665 - val_loss: 4.9016 - val_accuracy: 0.3846\n",
      "Epoch 7/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 4.7953 - accuracy: 0.3807 - val_loss: 4.6889 - val_accuracy: 0.4045\n",
      "Epoch 8/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 4.5882 - accuracy: 0.4054 - val_loss: 4.4873 - val_accuracy: 0.4296\n",
      "Epoch 9/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 4.3926 - accuracy: 0.4135 - val_loss: 4.2961 - val_accuracy: 0.4587\n",
      "Epoch 10/500\n",
      "231/231 [==============================] - 80s 345ms/step - loss: 4.2055 - accuracy: 0.4381 - val_loss: 4.1133 - val_accuracy: 0.4645\n",
      "Epoch 11/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 4.0258 - accuracy: 0.4394 - val_loss: 3.9387 - val_accuracy: 0.4663\n",
      "Epoch 12/500\n",
      "231/231 [==============================] - 80s 346ms/step - loss: 3.8558 - accuracy: 0.4394 - val_loss: 3.7719 - val_accuracy: 0.4685\n",
      "Epoch 13/500\n",
      "231/231 [==============================] - 78s 338ms/step - loss: 3.6919 - accuracy: 0.4400 - val_loss: 3.6125 - val_accuracy: 0.4693\n",
      "Epoch 14/500\n",
      "231/231 [==============================] - 80s 346ms/step - loss: 3.5358 - accuracy: 0.4474 - val_loss: 3.4602 - val_accuracy: 0.4699\n",
      "Epoch 15/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 3.3868 - accuracy: 0.4476 - val_loss: 3.3148 - val_accuracy: 0.4691\n",
      "Epoch 16/500\n",
      "231/231 [==============================] - 80s 344ms/step - loss: 3.2451 - accuracy: 0.4430 - val_loss: 3.1759 - val_accuracy: 0.4694\n",
      "Epoch 17/500\n",
      "231/231 [==============================] - 80s 348ms/step - loss: 3.1087 - accuracy: 0.4515 - val_loss: 3.0433 - val_accuracy: 0.4707\n",
      "Epoch 18/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 2.9792 - accuracy: 0.4472 - val_loss: 2.9168 - val_accuracy: 0.4721\n",
      "Epoch 19/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 2.8554 - accuracy: 0.4480 - val_loss: 2.7962 - val_accuracy: 0.4753\n",
      "Epoch 20/500\n",
      "231/231 [==============================] - 80s 345ms/step - loss: 2.7379 - accuracy: 0.4596 - val_loss: 2.6813 - val_accuracy: 0.4773\n",
      "Epoch 21/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 2.6250 - accuracy: 0.4609 - val_loss: 2.5717 - val_accuracy: 0.4816\n",
      "Epoch 22/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 2.5185 - accuracy: 0.4593 - val_loss: 2.4674 - val_accuracy: 0.4833\n",
      "Epoch 23/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 2.4162 - accuracy: 0.4678 - val_loss: 2.3681 - val_accuracy: 0.4909\n",
      "Epoch 24/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 2.3195 - accuracy: 0.4690 - val_loss: 2.2733 - val_accuracy: 0.5018\n",
      "Epoch 25/500\n",
      "231/231 [==============================] - 80s 346ms/step - loss: 2.2253 - accuracy: 0.4854 - val_loss: 2.1825 - val_accuracy: 0.5080\n",
      "Epoch 26/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 2.1353 - accuracy: 0.5004 - val_loss: 2.0950 - val_accuracy: 0.5105\n",
      "Epoch 27/500\n",
      "231/231 [==============================] - 79s 344ms/step - loss: 2.0481 - accuracy: 0.5050 - val_loss: 2.0103 - val_accuracy: 0.5157\n",
      "Epoch 28/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 1.9637 - accuracy: 0.5206 - val_loss: 1.9289 - val_accuracy: 0.5201\n",
      "Epoch 29/500\n",
      "231/231 [==============================] - 78s 338ms/step - loss: 1.8825 - accuracy: 0.5329 - val_loss: 1.8528 - val_accuracy: 0.5227\n",
      "Epoch 30/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 1.8067 - accuracy: 0.5411 - val_loss: 1.7814 - val_accuracy: 0.5272\n",
      "Epoch 31/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 1.7384 - accuracy: 0.5451 - val_loss: 1.7146 - val_accuracy: 0.5318\n",
      "Epoch 32/500\n",
      "231/231 [==============================] - 80s 347ms/step - loss: 1.6702 - accuracy: 0.5522 - val_loss: 1.6523 - val_accuracy: 0.5375\n",
      "Epoch 33/500\n",
      "231/231 [==============================] - 80s 346ms/step - loss: 1.6083 - accuracy: 0.5573 - val_loss: 1.5935 - val_accuracy: 0.5427\n",
      "Epoch 34/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 1.5492 - accuracy: 0.5612 - val_loss: 1.5395 - val_accuracy: 0.5476\n",
      "Epoch 35/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 1.4939 - accuracy: 0.5718 - val_loss: 1.4876 - val_accuracy: 0.5498\n",
      "Epoch 36/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 1.4426 - accuracy: 0.5765 - val_loss: 1.4397 - val_accuracy: 0.5552\n",
      "Epoch 37/500\n",
      "231/231 [==============================] - 80s 345ms/step - loss: 1.3937 - accuracy: 0.5773 - val_loss: 1.3956 - val_accuracy: 0.5563\n",
      "Epoch 38/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 1.3485 - accuracy: 0.5819 - val_loss: 1.3540 - val_accuracy: 0.5617\n",
      "Epoch 39/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 1.3067 - accuracy: 0.5885 - val_loss: 1.3159 - val_accuracy: 0.5626\n",
      "Epoch 40/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 1.2693 - accuracy: 0.5879 - val_loss: 1.2803 - val_accuracy: 0.5645\n",
      "Epoch 41/500\n",
      "231/231 [==============================] - 79s 344ms/step - loss: 1.2329 - accuracy: 0.5954 - val_loss: 1.2474 - val_accuracy: 0.5678\n",
      "Epoch 42/500\n",
      "231/231 [==============================] - 78s 338ms/step - loss: 1.1965 - accuracy: 0.5946 - val_loss: 1.2162 - val_accuracy: 0.5705\n",
      "Epoch 43/500\n",
      "231/231 [==============================] - 80s 347ms/step - loss: 1.1648 - accuracy: 0.6007 - val_loss: 1.1885 - val_accuracy: 0.5740\n",
      "Epoch 44/500\n",
      "231/231 [==============================] - 80s 346ms/step - loss: 1.1369 - accuracy: 0.6055 - val_loss: 1.1634 - val_accuracy: 0.5759\n",
      "Epoch 45/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 1.1059 - accuracy: 0.6080 - val_loss: 1.1386 - val_accuracy: 0.5786\n",
      "Epoch 46/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 1.0838 - accuracy: 0.6108 - val_loss: 1.1168 - val_accuracy: 0.5817\n",
      "Epoch 47/500\n",
      "231/231 [==============================] - 79s 340ms/step - loss: 1.0578 - accuracy: 0.6174 - val_loss: 1.0965 - val_accuracy: 0.5840\n",
      "Epoch 48/500\n",
      "231/231 [==============================] - 79s 340ms/step - loss: 1.0345 - accuracy: 0.6204 - val_loss: 1.0780 - val_accuracy: 0.5854\n",
      "Epoch 49/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 1.0163 - accuracy: 0.6220 - val_loss: 1.0615 - val_accuracy: 0.5858\n",
      "Epoch 50/500\n",
      "231/231 [==============================] - 78s 337ms/step - loss: 0.9980 - accuracy: 0.6268 - val_loss: 1.0480 - val_accuracy: 0.5876\n",
      "Epoch 51/500\n",
      "231/231 [==============================] - 79s 343ms/step - loss: 0.9799 - accuracy: 0.6318 - val_loss: 1.0339 - val_accuracy: 0.5895\n",
      "Epoch 52/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 0.9618 - accuracy: 0.6341 - val_loss: 1.0211 - val_accuracy: 0.5911\n",
      "Epoch 53/500\n",
      "231/231 [==============================] - 78s 337ms/step - loss: 0.9531 - accuracy: 0.6353 - val_loss: 1.0106 - val_accuracy: 0.5930\n",
      "Epoch 54/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 0.9345 - accuracy: 0.6383 - val_loss: 1.0011 - val_accuracy: 0.5936\n",
      "Epoch 55/500\n",
      "231/231 [==============================] - 79s 340ms/step - loss: 0.9253 - accuracy: 0.6359 - val_loss: 0.9927 - val_accuracy: 0.5947\n",
      "Epoch 56/500\n",
      "231/231 [==============================] - 78s 340ms/step - loss: 0.9136 - accuracy: 0.6431 - val_loss: 0.9854 - val_accuracy: 0.5949\n",
      "Epoch 57/500\n",
      "231/231 [==============================] - 78s 337ms/step - loss: 0.9032 - accuracy: 0.6470 - val_loss: 0.9782 - val_accuracy: 0.5952\n",
      "Epoch 58/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 0.8968 - accuracy: 0.6512 - val_loss: 0.9727 - val_accuracy: 0.5956\n",
      "Epoch 59/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.8879 - accuracy: 0.6486 - val_loss: 0.9674 - val_accuracy: 0.5971\n",
      "Epoch 60/500\n",
      "231/231 [==============================] - 80s 347ms/step - loss: 0.8791 - accuracy: 0.6486 - val_loss: 0.9644 - val_accuracy: 0.5988\n",
      "Epoch 61/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.8729 - accuracy: 0.6534 - val_loss: 0.9613 - val_accuracy: 0.5966\n",
      "Epoch 62/500\n",
      "231/231 [==============================] - 79s 344ms/step - loss: 0.8639 - accuracy: 0.6563 - val_loss: 0.9578 - val_accuracy: 0.5979\n",
      "Epoch 63/500\n",
      "231/231 [==============================] - 79s 344ms/step - loss: 0.8597 - accuracy: 0.6559 - val_loss: 0.9554 - val_accuracy: 0.5979\n",
      "Epoch 64/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.8541 - accuracy: 0.6591 - val_loss: 0.9533 - val_accuracy: 0.5975\n",
      "Epoch 65/500\n",
      "231/231 [==============================] - 80s 346ms/step - loss: 0.8440 - accuracy: 0.6617 - val_loss: 0.9500 - val_accuracy: 0.5999\n",
      "Epoch 66/500\n",
      "231/231 [==============================] - 79s 340ms/step - loss: 0.8449 - accuracy: 0.6662 - val_loss: 0.9478 - val_accuracy: 0.6001\n",
      "Epoch 67/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.8364 - accuracy: 0.6691 - val_loss: 0.9480 - val_accuracy: 0.6020\n",
      "Epoch 68/500\n",
      "231/231 [==============================] - 80s 347ms/step - loss: 0.8319 - accuracy: 0.6683 - val_loss: 0.9464 - val_accuracy: 0.5993\n",
      "Epoch 69/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.8296 - accuracy: 0.6685 - val_loss: 0.9445 - val_accuracy: 0.6016\n",
      "Epoch 70/500\n",
      "231/231 [==============================] - 79s 340ms/step - loss: 0.8252 - accuracy: 0.6698 - val_loss: 0.9430 - val_accuracy: 0.6002\n",
      "Epoch 71/500\n",
      "231/231 [==============================] - 78s 340ms/step - loss: 0.8169 - accuracy: 0.6765 - val_loss: 0.9425 - val_accuracy: 0.6010\n",
      "Epoch 72/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 0.8150 - accuracy: 0.6731 - val_loss: 0.9416 - val_accuracy: 0.6027\n",
      "Epoch 73/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 0.8130 - accuracy: 0.6752 - val_loss: 0.9410 - val_accuracy: 0.6015\n",
      "Epoch 74/500\n",
      "231/231 [==============================] - 77s 333ms/step - loss: 0.8067 - accuracy: 0.6772 - val_loss: 0.9428 - val_accuracy: 0.6037\n",
      "Epoch 75/500\n",
      "231/231 [==============================] - 78s 336ms/step - loss: 0.8008 - accuracy: 0.6795 - val_loss: 0.9406 - val_accuracy: 0.6051\n",
      "Epoch 76/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.8005 - accuracy: 0.6849 - val_loss: 0.9423 - val_accuracy: 0.6051\n",
      "Epoch 77/500\n",
      "231/231 [==============================] - 78s 337ms/step - loss: 0.7973 - accuracy: 0.6843 - val_loss: 0.9404 - val_accuracy: 0.6046\n",
      "Epoch 78/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.7923 - accuracy: 0.6855 - val_loss: 0.9428 - val_accuracy: 0.6051\n",
      "Epoch 79/500\n",
      "231/231 [==============================] - 78s 337ms/step - loss: 0.7929 - accuracy: 0.6824 - val_loss: 0.9394 - val_accuracy: 0.6046\n",
      "Epoch 80/500\n",
      "231/231 [==============================] - 79s 340ms/step - loss: 0.7838 - accuracy: 0.6882 - val_loss: 0.9402 - val_accuracy: 0.6057\n",
      "Epoch 81/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.7829 - accuracy: 0.6889 - val_loss: 0.9408 - val_accuracy: 0.6065\n",
      "Epoch 82/500\n",
      "231/231 [==============================] - 79s 340ms/step - loss: 0.7793 - accuracy: 0.6905 - val_loss: 0.9420 - val_accuracy: 0.6051\n",
      "Epoch 83/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 0.7791 - accuracy: 0.6902 - val_loss: 0.9387 - val_accuracy: 0.6059\n",
      "Epoch 84/500\n",
      "231/231 [==============================] - 79s 341ms/step - loss: 0.7727 - accuracy: 0.6934 - val_loss: 0.9417 - val_accuracy: 0.6065\n",
      "Epoch 85/500\n",
      "231/231 [==============================] - 78s 337ms/step - loss: 0.7656 - accuracy: 0.6977 - val_loss: 0.9422 - val_accuracy: 0.6072\n",
      "Epoch 86/500\n",
      "231/231 [==============================] - 78s 340ms/step - loss: 0.7682 - accuracy: 0.6957 - val_loss: 0.9446 - val_accuracy: 0.6070\n",
      "Epoch 87/500\n",
      "231/231 [==============================] - 78s 339ms/step - loss: 0.7639 - accuracy: 0.6976 - val_loss: 0.9410 - val_accuracy: 0.6064\n",
      "Epoch 88/500\n",
      "231/231 [==============================] - 77s 335ms/step - loss: 0.7643 - accuracy: 0.6969 - val_loss: 0.9402 - val_accuracy: 0.6043\n",
      "Epoch 89/500\n",
      "231/231 [==============================] - 78s 336ms/step - loss: 0.7584 - accuracy: 0.6970 - val_loss: 0.9453 - val_accuracy: 0.6061\n",
      "Epoch 90/500\n",
      "231/231 [==============================] - 79s 342ms/step - loss: 0.7542 - accuracy: 0.7068 - val_loss: 0.9422 - val_accuracy: 0.6053\n",
      "Epoch 91/500\n",
      "231/231 [==============================] - 80s 346ms/step - loss: 0.7506 - accuracy: 0.7064 - val_loss: 0.9454 - val_accuracy: 0.6050\n",
      "Epoch 92/500\n",
      "200/231 [========================>.....] - ETA: 9s - loss: 0.7497 - accuracy: 0.7063"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history_lstm \u001b[38;5;241m=\u001b[39m \u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmyCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/dbs/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_lstm = lstm.fit(X_train, y_train,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        batch_size=64, \n",
    "                        epochs=500, \n",
    "                        callbacks=myCallback())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
